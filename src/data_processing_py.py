# -*- coding: utf-8 -*-
"""data_processing.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W17EZzluPC68QvhniTPquEinygpbRRsu
"""

import pandas as pd
import numpy as np
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split

import datetime


# 1. Custom Transformer: Feature Generator
class FeatureEngineer(BaseEstimator, TransformerMixin):
    def __init__(self):
        pass

    def fit(self, X, y=None):
        return self

    def transform(self, X):
        df = X.copy()

        # Convert datetime
        df["TransactionStartTime"] = pd.to_datetime(df["TransactionStartTime"])

        # Extract time-based features
        df["transaction_hour"] = df["TransactionStartTime"].dt.hour
        df["transaction_day"] = df["TransactionStartTime"].dt.day
        df["transaction_month"] = df["TransactionStartTime"].dt.month
        df["transaction_year"] = df["TransactionStartTime"].dt.year

        # Aggregate features (assumes one row per transaction)
        agg_df = df.groupby("CustomerId").agg({
            "Amount": ["sum", "mean", "count", "std"]
        })
        agg_df.columns = [
            "total_amount", "avg_amount", "transaction_count", "amount_std"
        ]
        agg_df = agg_df.reset_index()

        # Merge back with original data
        df = df.merge(agg_df, on="CustomerId", how="left")

        return df


# 2. Create preprocessing pipeline
def create_pipeline():
    # Define feature groups
    numerical_features = ["total_amount", "avg_amount", "transaction_count", "amount_std", "transaction_hour", "transaction_day", "transaction_month"]
    categorical_features = ["ProductCategory", "ChannelId", "CurrencyCode", "CountryCode"]

    # Pipelines
    numeric_pipeline = Pipeline([
        ("imputer", SimpleImputer(strategy="median")),
        ("scaler", StandardScaler())
    ])

    categorical_pipeline = Pipeline([
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("encoder", OneHotEncoder(handle_unknown="ignore"))
    ])

    preprocessor = ColumnTransformer(transformers=[
        ("num", numeric_pipeline, numerical_features),
        ("cat", categorical_pipeline, categorical_features)
    ])

    full_pipeline = Pipeline(steps=[
        ("feature_engineer", FeatureEngineer()),
        ("preprocessor", preprocessor)
    ])

    return full_pipeline


# 3.for trainin usageg script or EDA
if __name__ == "__main__":
    df = pd.read_csv("data.csv")

    pipeline = create_pipeline()
    processed = pipeline.fit_transform(df)

    print("Transformed data shape:", processed.shape)